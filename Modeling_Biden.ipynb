{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweet_Biden = pd.read_csv((\"/Users/bahtinur/Desktop/Tweet/Biden.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330752855066763264</td>\n",
       "      <td>2020-11-23 05:59:39</td>\n",
       "      <td>whitehouse how about u post a plan   cv , don...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330752854072692736</td>\n",
       "      <td>2020-11-23 05:59:39</td>\n",
       "      <td>biden and harris will have a hard time getting...</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1330752853913128960</td>\n",
       "      <td>2020-11-23 05:59:39</td>\n",
       "      <td>joenbc  jonlemire with not a shred of evidenc...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1330752851543470081</td>\n",
       "      <td>2020-11-23 05:59:38</td>\n",
       "      <td>blinken was a key adviser to biden when the s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330752850889203719</td>\n",
       "      <td>2020-11-23 05:59:38</td>\n",
       "      <td>snl got jim carrey to okay biden because he is...</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1330752855066763264  2020-11-23 05:59:39   \n",
       "1  1330752854072692736  2020-11-23 05:59:39   \n",
       "2  1330752853913128960  2020-11-23 05:59:39   \n",
       "3  1330752851543470081  2020-11-23 05:59:38   \n",
       "4  1330752850889203719  2020-11-23 05:59:38   \n",
       "\n",
       "                                           full_text  Sentiment SentimentClass  \n",
       "0   whitehouse how about u post a plan   cv , don...   0.250000       Positive  \n",
       "1  biden and harris will have a hard time getting...   0.254167       Positive  \n",
       "2   joenbc  jonlemire with not a shred of evidenc...   0.000000        Neutral  \n",
       "3   blinken was a key adviser to biden when the s...   0.000000        Neutral  \n",
       "4  snl got jim carrey to okay biden because he is...  -0.150000       Negative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_Biden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     whitehouse how about u post a plan   cv , don...\n",
      "1    biden and harris will have a hard time getting...\n",
      "2     joenbc  jonlemire with not a shred of evidenc...\n",
      "3     blinken was a key adviser to biden when the s...\n",
      "4    snl got jim carrey to okay biden because he is...\n",
      "Name: full_text, dtype: object\n",
      "-------Remove Stop Word------\n",
      "0    whitehouse u post plan cv , donald's exit plan...\n",
      "1    biden harris hard time getting things done dem...\n",
      "2    joenbc jonlemire shred evidence back statement...\n",
      "3    blinken key adviser biden senator voted author...\n",
      "4          snl got jim carrey okay biden also retarded\n",
      "Name: StopWords, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop = stopwords.words(\"english\")\n",
    "\n",
    "print((tweet_Biden['full_text']).head())\n",
    "print('-------Remove Stop Word------')\n",
    "tweet_Biden['StopWords'] = tweet_Biden['full_text'].astype(str).apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "print((tweet_Biden['StopWords']).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    whitehouse u post plan cv , donald's exit plan...\n",
      "1    biden harris hard time getting things done dem...\n",
      "2    joenbc jonlemire shred evidence back statement...\n",
      "3    blinken key adviser biden senator voted author...\n",
      "4          snl got jim carrey okay biden also retarded\n",
      "Name: StopWords, dtype: object\n",
      "-------Stemming------\n",
      "0    whitehous u post plan cv , donald' exit plan, ...\n",
      "1    biden harri hard time get thing done dem win s...\n",
      "2    joenbc jonlemir shred evid back statements, tw...\n",
      "3    blinken key advis biden senat vote author use ...\n",
      "4            snl got jim carrey okay biden also retard\n",
      "Name: Stemming, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "print((tweet_Biden['StopWords']).head())\n",
    "print('-------Stemming------')\n",
    "tweet_Biden['Stemming'] = tweet_Biden['StopWords'].astype(str).apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\n",
    "print((tweet_Biden['Stemming']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    whitehous u post plan cv , donald' exit plan, ...\n",
      "1    biden harri hard time get thing done dem win s...\n",
      "2    joenbc jonlemir shred evid back statements, tw...\n",
      "3    blinken key advis biden senat vote author use ...\n",
      "4            snl got jim carrey okay biden also retard\n",
      "Name: Stemming, dtype: object\n",
      "-------Lemmazation------\n",
      "0    whitehous u post plan cv , donald' exit plan, ...\n",
      "1    biden harri hard time get thing done dem win s...\n",
      "2    joenbc jonlemir shred evid back statements, tw...\n",
      "3    blinken key advis biden senat vote author use ...\n",
      "4            snl got jim carrey okay biden also retard\n",
      "Name: Lemmatizing, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print((tweet_Biden['Stemming']).head())\n",
    "print('-------Lemmazation------')\n",
    "tweet_Biden['Lemmatizing'] = tweet_Biden['Stemming'].astype(str).apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "print((tweet_Biden['Lemmatizing']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "text = tweet_Biden[\"Lemmatizing\"]\n",
    "\n",
    "for i in range(0,len(text)):\n",
    "    textB = TextBlob(text[i])\n",
    "    sentiment = textB.sentiment.polarity\n",
    "    tweet_Biden.at[i, 'Sentiment'] = sentiment\n",
    "    if sentiment <0.00:\n",
    "        SentimentClass = 'Negative'\n",
    "        tweet_Biden.at[i, 'SentimentClass'] = SentimentClass \n",
    "    elif sentiment >0.00:\n",
    "        SentimentClass = 'Positive'\n",
    "        tweet_Biden.at[i, 'SentimentClass'] = SentimentClass \n",
    "    else:\n",
    "        SentimentClass = 'Neutral'\n",
    "        tweet_Biden.at[i, 'SentimentClass'] = SentimentClass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweet_Biden.to_csv(\"/Users/bahtinur/Desktop/Tweet/Biden.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweet_Biden = pd.read_csv((\"/Users/bahtinur/Desktop/Tweet/Biden.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentClass</th>\n",
       "      <th>Lemmatizing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330752855066763264</td>\n",
       "      <td>2020-11-23 05:59:39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>whitehous u post plan cv , donald' exit plan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330752854072692736</td>\n",
       "      <td>2020-11-23 05:59:39</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>Positive</td>\n",
       "      <td>biden harri hard time get thing done dem win s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1330752853913128960</td>\n",
       "      <td>2020-11-23 05:59:39</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>Negative</td>\n",
       "      <td>joenbc jonlemir shred evid back statements, tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1330752851543470081</td>\n",
       "      <td>2020-11-23 05:59:38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>blinken key advis biden senat vote author use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330752850889203719</td>\n",
       "      <td>2020-11-23 05:59:38</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>snl got jim carrey okay biden also retard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  Sentiment SentimentClass  \\\n",
       "0  1330752855066763264  2020-11-23 05:59:39   0.000000        Neutral   \n",
       "1  1330752854072692736  2020-11-23 05:59:39   0.254167       Positive   \n",
       "2  1330752853913128960  2020-11-23 05:59:39  -0.083333       Negative   \n",
       "3  1330752851543470081  2020-11-23 05:59:38   0.000000        Neutral   \n",
       "4  1330752850889203719  2020-11-23 05:59:38  -0.200000       Negative   \n",
       "\n",
       "                                         Lemmatizing  \n",
       "0  whitehous u post plan cv , donald' exit plan, ...  \n",
       "1  biden harri hard time get thing done dem win s...  \n",
       "2  joenbc jonlemir shred evid back statements, tw...  \n",
       "3  blinken key advis biden senat vote author use ...  \n",
       "4          snl got jim carrey okay biden also retard  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_Biden.drop(['StopWords', 'Stemming', 'full_text'], axis=1, inplace = True)\n",
    "\n",
    "tweet_Biden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentClass</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330752855066763264</td>\n",
       "      <td>2020-11-23 05:59:39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>whitehous u post plan cv , donald' exit plan, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330752854072692736</td>\n",
       "      <td>2020-11-23 05:59:39</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>Positive</td>\n",
       "      <td>biden harri hard time get thing done dem win s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1330752853913128960</td>\n",
       "      <td>2020-11-23 05:59:39</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>Negative</td>\n",
       "      <td>joenbc jonlemir shred evid back statements, tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1330752851543470081</td>\n",
       "      <td>2020-11-23 05:59:38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>blinken key advis biden senat vote author use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330752850889203719</td>\n",
       "      <td>2020-11-23 05:59:38</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>snl got jim carrey okay biden also retard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  Sentiment SentimentClass  \\\n",
       "0  1330752855066763264  2020-11-23 05:59:39   0.000000        Neutral   \n",
       "1  1330752854072692736  2020-11-23 05:59:39   0.254167       Positive   \n",
       "2  1330752853913128960  2020-11-23 05:59:39  -0.083333       Negative   \n",
       "3  1330752851543470081  2020-11-23 05:59:38   0.000000        Neutral   \n",
       "4  1330752850889203719  2020-11-23 05:59:38  -0.200000       Negative   \n",
       "\n",
       "                                                text  \n",
       "0  whitehous u post plan cv , donald' exit plan, ...  \n",
       "1  biden harri hard time get thing done dem win s...  \n",
       "2  joenbc jonlemir shred evid back statements, tw...  \n",
       "3  blinken key advis biden senat vote author use ...  \n",
       "4          snl got jim carrey okay biden also retard  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_Biden.rename(columns={'Lemmatizing':'text'}, inplace=True)\n",
    "tweet_Biden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = {'Positive':'1','Negative':'2','Neutral':'0'}\n",
    "tweet_Biden['SentimentClass'] = tweet_Biden['SentimentClass'].map(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4862 entries, 0 to 4861\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              4862 non-null   int64  \n",
      " 1   created_at      4862 non-null   object \n",
      " 2   Sentiment       4862 non-null   float64\n",
      " 3   SentimentClass  4862 non-null   object \n",
      " 4   text            4861 non-null   object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 227.9+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_Biden.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_Biden[tweet_Biden.isna().any(axis=1)]\n",
    "tweet_Biden = tweet_Biden.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4861 entries, 0 to 4861\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              4861 non-null   int64  \n",
      " 1   created_at      4861 non-null   object \n",
      " 2   Sentiment       4861 non-null   float64\n",
      " 3   SentimentClass  4861 non-null   object \n",
      " 4   text            4861 non-null   object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 227.9+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_Biden.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     2444\n",
       "Positive    1667\n",
       "Negative     750\n",
       "Name: SentimentClass, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = {'1':'Positive','2':'Negative','0':'Neutral'}\n",
    "tweet_Biden['SentimentClass'] = tweet_Biden['SentimentClass'].map(sent)\n",
    "tweet_Biden['SentimentClass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tweet_Biden['SentimentClass'].value_counts().plot(kind='bar', width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweet_Biden.iloc[:, 4].values\n",
    "y = tweet_Biden.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer (max_features=250, min_df=7, max_df=0.8)\n",
    "X = vectorizer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4861, 250), (4861,), (4374, 250), (4374,), (487, 250), (487,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246   4   3]\n",
      " [ 39 119   3]\n",
      " [ 38   7  28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85       253\n",
      "           1       0.92      0.74      0.82       161\n",
      "           2       0.82      0.38      0.52        73\n",
      "\n",
      "    accuracy                           0.81       487\n",
      "   macro avg       0.83      0.70      0.73       487\n",
      "weighted avg       0.82      0.81      0.79       487\n",
      "\n",
      "0.8069815195071869\n",
      "The accuracy of the Random Forest model is 0.8069815195071869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_predRF = rfc.predict(X_test)\n",
    "score_RF = rfc.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predRF))\n",
    "print(classification_report(y_test,y_predRF))\n",
    "print(accuracy_score(y_test, y_predRF))\n",
    "print('The accuracy of the Random Forest model is', score_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[251   2   0]\n",
      " [ 46 112   3]\n",
      " [ 40   8  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.85       253\n",
      "           1       0.92      0.70      0.79       161\n",
      "           2       0.89      0.34      0.50        73\n",
      "\n",
      "    accuracy                           0.80       487\n",
      "   macro avg       0.85      0.68      0.71       487\n",
      "weighted avg       0.82      0.80      0.78       487\n",
      "\n",
      "0.7967145790554415\n",
      "The accuracy of the Support Vector Machine model is 0.7967145790554415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "y_predSVC = svclassifier.predict(X_test)\n",
    "score_SVC = svclassifier.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predSVC))\n",
    "print(classification_report(y_test,y_predSVC))\n",
    "print(accuracy_score(y_test, y_predSVC))\n",
    "print('The accuracy of the Support Vector Machine model is', score_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246   7   0]\n",
      " [ 51 109   1]\n",
      " [ 41  12  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.97      0.83       253\n",
      "           1       0.85      0.68      0.75       161\n",
      "           2       0.95      0.27      0.43        73\n",
      "\n",
      "    accuracy                           0.77       487\n",
      "   macro avg       0.84      0.64      0.67       487\n",
      "weighted avg       0.80      0.77      0.75       487\n",
      "\n",
      "0.7700205338809035\n",
      "The accuracy of the MultinomialNB model is 0.7700205338809035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "y_predNB = NB_model.predict(X_test)\n",
    "score_NB = NB_model.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predNB))\n",
    "print(classification_report(y_test,y_predNB))\n",
    "print(accuracy_score(y_test, y_predNB))\n",
    "print('The accuracy of the MultinomialNB model is', score_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[248   4   1]\n",
      " [ 47 112   2]\n",
      " [ 39   8  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84       253\n",
      "           1       0.90      0.70      0.79       161\n",
      "           2       0.90      0.36      0.51        73\n",
      "\n",
      "    accuracy                           0.79       487\n",
      "   macro avg       0.85      0.68      0.71       487\n",
      "weighted avg       0.82      0.79      0.78       487\n",
      "\n",
      "0.7926078028747433\n",
      "The accuracy of the Logistic Regression model is 0.7926078028747433\n"
     ]
    }
   ],
   "source": [
    "LR_model = LogisticRegression(solver='lbfgs')\n",
    "LR_model.fit(X_train, y_train)\n",
    "y_predLR = LR_model.predict(X_test)\n",
    "score_LR = LR_model.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predLR))\n",
    "print(classification_report(y_test,y_predLR))\n",
    "print(accuracy_score(y_test, y_predLR))\n",
    "print('The accuracy of the Logistic Regression model is', score_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[212  29  12]\n",
      " [ 76  83   2]\n",
      " [ 45  16  12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.72       253\n",
      "           1       0.65      0.52      0.57       161\n",
      "           2       0.46      0.16      0.24        73\n",
      "\n",
      "    accuracy                           0.63       487\n",
      "   macro avg       0.58      0.51      0.51       487\n",
      "weighted avg       0.61      0.63      0.60       487\n",
      "\n",
      "0.6303901437371663\n",
      "The accuracy of the KNN model is 0.6303901437371663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier #K nearest neighbors\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=4)\n",
    "model_KNN.fit(X_train, y_train)\n",
    "y_predKNN = model_KNN.predict(X_test)\n",
    "score_KNN = model_KNN.score(X_test,y_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_predKNN))\n",
    "print(classification_report(y_test,y_predKNN))\n",
    "print(accuracy_score(y_test, y_predKNN))\n",
    "print('The accuracy of the KNN model is', score_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+\n",
      "|     CLASSIFICATION     | ACCURACY |\n",
      "+========================+==========+\n",
      "| LogisticRegression     | 0.793    |\n",
      "+------------------------+----------+\n",
      "| RandomForest           | 0.807    |\n",
      "+------------------------+----------+\n",
      "| K-NearestNeighbors     | 0.630    |\n",
      "+------------------------+----------+\n",
      "| MultinominalNaiveBayes | 0.770    |\n",
      "+------------------------+----------+\n",
      "| SupportVector          | 0.797    |\n",
      "+------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from texttable import Texttable\n",
    "# texttable takes the first reocrd in the list as the column names\n",
    "# of the table\n",
    "l = [[\"CLASSIFICATION\", \"ACCURACY\"],['LogisticRegression', score_LR],['RandomForest', score_RF],['K-NearestNeighbors',score_KNN],['MultinominalNaiveBayes',score_NB], ['SupportVector', score_SVC]]\n",
    "table = Texttable()\n",
    "table.add_rows(l)\n",
    "print(table.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
