{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweet_vaccine = pd.read_csv((\"/Users/bahtinur/Desktop/Tweet/vaccine.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330833397120454656</td>\n",
       "      <td>2020-11-23 11:19:42</td>\n",
       "      <td>oxford uni newsletter confirms the key princip...</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330833393026621441</td>\n",
       "      <td>2020-11-23 11:19:41</td>\n",
       "      <td>kaarnama   vinayak jain bcoz vaccine isafe by...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1330833388987699201</td>\n",
       "      <td>2020-11-23 11:19:40</td>\n",
       "      <td>kieranmurphy   lilyallen yes it is. this is t...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1330833387469332485</td>\n",
       "      <td>2020-11-23 11:19:39</td>\n",
       "      <td>lynnehall  uniofoxford   is enough to protect...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330833386185908225</td>\n",
       "      <td>2020-11-23 11:19:39</td>\n",
       "      <td>cjhancock ah, vaccine peak. one standout sess...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1330833397120454656  2020-11-23 11:19:42   \n",
       "1  1330833393026621441  2020-11-23 11:19:41   \n",
       "2  1330833388987699201  2020-11-23 11:19:40   \n",
       "3  1330833387469332485  2020-11-23 11:19:39   \n",
       "4  1330833386185908225  2020-11-23 11:19:39   \n",
       "\n",
       "                                           full_text  Sentiment SentimentClass  \n",
       "0  oxford uni newsletter confirms the key princip...  -0.200000       Negative  \n",
       "1   kaarnama   vinayak jain bcoz vaccine isafe by...   0.000000        Neutral  \n",
       "2   kieranmurphy   lilyallen yes it is. this is t...   0.136364       Positive  \n",
       "3   lynnehall  uniofoxford   is enough to protect...   0.100000       Positive  \n",
       "4   cjhancock ah, vaccine peak. one standout sess...   0.000000        Neutral  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vaccine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    oxford uni newsletter confirms the key princip...\n",
      "1     kaarnama   vinayak jain bcoz vaccine isafe by...\n",
      "2     kieranmurphy   lilyallen yes it is. this is t...\n",
      "3     lynnehall  uniofoxford   is enough to protect...\n",
      "4     cjhancock ah, vaccine peak. one standout sess...\n",
      "Name: full_text, dtype: object\n",
      "-------Remove Stop Word------\n",
      "0    oxford uni newsletter confirms key principle a...\n",
      "1    kaarnama vinayak jain bcoz vaccine isafe kafir...\n",
      "2    kieranmurphy lilyallen yes is. oxford/astrazen...\n",
      "3    lynnehall uniofoxford enough protect whole cou...\n",
      "4    cjhancock ah, vaccine peak. one standout sessi...\n",
      "Name: StopWords, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop = stopwords.words(\"english\")\n",
    "\n",
    "print((tweet_vaccine['full_text']).head())\n",
    "print('-------Remove Stop Word------')\n",
    "tweet_vaccine['StopWords'] = tweet_vaccine['full_text'].astype(str).apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "print((tweet_vaccine['StopWords']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    oxford uni newsletter confirms key principle a...\n",
      "1    kaarnama vinayak jain bcoz vaccine isafe kafir...\n",
      "2    kieranmurphy lilyallen yes is. oxford/astrazen...\n",
      "3    lynnehall uniofoxford enough protect whole cou...\n",
      "4    cjhancock ah, vaccine peak. one standout sessi...\n",
      "Name: StopWords, dtype: object\n",
      "-------Stemming------\n",
      "0    oxford uni newslett confirm key principl acces...\n",
      "1    kaarnama vinayak jain bcoz vaccin isaf kafir k...\n",
      "2    kieranmurphi lilyallen ye is. oxford/astrazene...\n",
      "3    lynnehal uniofoxford enough protect whole coun...\n",
      "4    cjhancock ah, vaccin peak. one standout sessio...\n",
      "Name: Stemming, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "print((tweet_vaccine['StopWords']).head())\n",
    "print('-------Stemming------')\n",
    "tweet_vaccine['Stemming'] = tweet_vaccine['StopWords'].astype(str).apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\n",
    "print((tweet_vaccine['Stemming']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    oxford uni newslett confirm key principl acces...\n",
      "1    kaarnama vinayak jain bcoz vaccin isaf kafir k...\n",
      "2    kieranmurphi lilyallen ye is. oxford/astrazene...\n",
      "3    lynnehal uniofoxford enough protect whole coun...\n",
      "4    cjhancock ah, vaccin peak. one standout sessio...\n",
      "Name: Stemming, dtype: object\n",
      "-------Lemmazation------\n",
      "0    oxford uni newslett confirm key principl acces...\n",
      "1    kaarnama vinayak jain bcoz vaccin isaf kafir k...\n",
      "2    kieranmurphi lilyallen ye is. oxford/astrazene...\n",
      "3    lynnehal uniofoxford enough protect whole coun...\n",
      "4    cjhancock ah, vaccin peak. one standout sessio...\n",
      "Name: Lemmatizing, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print((tweet_vaccine['Stemming']).head())\n",
    "print('-------Lemmazation------')\n",
    "tweet_vaccine['Lemmatizing'] = tweet_vaccine['Stemming'].astype(str).apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "print((tweet_vaccine['Lemmatizing']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "text = tweet_vaccine[\"Lemmatizing\"]\n",
    "\n",
    "for i in range(0,len(text)):\n",
    "    textB = TextBlob(text[i])\n",
    "    sentiment = textB.sentiment.polarity\n",
    "    tweet_vaccine.at[i, 'Sentiment'] = sentiment\n",
    "    if sentiment <0.00:\n",
    "        SentimentClass = 'Negative'\n",
    "        tweet_vaccine.at[i, 'SentimentClass'] = SentimentClass \n",
    "    elif sentiment >0.00:\n",
    "        SentimentClass = 'Positive'\n",
    "        tweet_vaccine.at[i, 'SentimentClass'] = SentimentClass \n",
    "    else:\n",
    "        SentimentClass = 'Neutral'\n",
    "        tweet_vaccine.at[i, 'SentimentClass'] = SentimentClass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweet_vaccine.to_csv(\"/Users/bahtinur/Desktop/Tweet/vaccine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweet_vaccine = pd.read_csv((\"/Users/bahtinur/Desktop/Tweet/vaccine.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentClass</th>\n",
       "      <th>Lemmatizing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330833397120454656</td>\n",
       "      <td>2020-11-23 11:19:42</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>oxford uni newslett confirm key principl acces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330833393026621441</td>\n",
       "      <td>2020-11-23 11:19:41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>kaarnama vinayak jain bcoz vaccin isaf kafir k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1330833388987699201</td>\n",
       "      <td>2020-11-23 11:19:40</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>Positive</td>\n",
       "      <td>kieranmurphi lilyallen ye is. oxford/astrazene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1330833387469332485</td>\n",
       "      <td>2020-11-23 11:19:39</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>lynnehal uniofoxford enough protect whole coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330833386185908225</td>\n",
       "      <td>2020-11-23 11:19:39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>cjhancock ah, vaccin peak. one standout sessio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  Sentiment SentimentClass  \\\n",
       "0  1330833397120454656  2020-11-23 11:19:42  -0.200000       Negative   \n",
       "1  1330833393026621441  2020-11-23 11:19:41   0.000000        Neutral   \n",
       "2  1330833388987699201  2020-11-23 11:19:40   0.136364       Positive   \n",
       "3  1330833387469332485  2020-11-23 11:19:39   0.100000       Positive   \n",
       "4  1330833386185908225  2020-11-23 11:19:39   0.000000        Neutral   \n",
       "\n",
       "                                         Lemmatizing  \n",
       "0  oxford uni newslett confirm key principl acces...  \n",
       "1  kaarnama vinayak jain bcoz vaccin isaf kafir k...  \n",
       "2  kieranmurphi lilyallen ye is. oxford/astrazene...  \n",
       "3  lynnehal uniofoxford enough protect whole coun...  \n",
       "4  cjhancock ah, vaccin peak. one standout sessio...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vaccine.drop(['StopWords', 'Stemming', 'full_text'], axis=1, inplace = True)\n",
    "tweet_vaccine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentClass</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330833397120454656</td>\n",
       "      <td>2020-11-23 11:19:42</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>Negative</td>\n",
       "      <td>oxford uni newslett confirm key principl acces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330833393026621441</td>\n",
       "      <td>2020-11-23 11:19:41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>kaarnama vinayak jain bcoz vaccin isaf kafir k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1330833388987699201</td>\n",
       "      <td>2020-11-23 11:19:40</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>Positive</td>\n",
       "      <td>kieranmurphi lilyallen ye is. oxford/astrazene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1330833387469332485</td>\n",
       "      <td>2020-11-23 11:19:39</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>lynnehal uniofoxford enough protect whole coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330833386185908225</td>\n",
       "      <td>2020-11-23 11:19:39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>cjhancock ah, vaccin peak. one standout sessio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  Sentiment SentimentClass  \\\n",
       "0  1330833397120454656  2020-11-23 11:19:42  -0.200000       Negative   \n",
       "1  1330833393026621441  2020-11-23 11:19:41   0.000000        Neutral   \n",
       "2  1330833388987699201  2020-11-23 11:19:40   0.136364       Positive   \n",
       "3  1330833387469332485  2020-11-23 11:19:39   0.100000       Positive   \n",
       "4  1330833386185908225  2020-11-23 11:19:39   0.000000        Neutral   \n",
       "\n",
       "                                                text  \n",
       "0  oxford uni newslett confirm key principl acces...  \n",
       "1  kaarnama vinayak jain bcoz vaccin isaf kafir k...  \n",
       "2  kieranmurphi lilyallen ye is. oxford/astrazene...  \n",
       "3  lynnehal uniofoxford enough protect whole coun...  \n",
       "4  cjhancock ah, vaccin peak. one standout sessio...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vaccine.rename(columns={'Lemmatizing':'text'}, inplace=True)\n",
    "tweet_vaccine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = {'Positive':'1','Negative':'2','Neutral':'0'}\n",
    "tweet_vaccine['SentimentClass'] = tweet_vaccine['SentimentClass'].map(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4670 entries, 0 to 4669\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              4670 non-null   int64  \n",
      " 1   created_at      4670 non-null   object \n",
      " 2   Sentiment       4670 non-null   float64\n",
      " 3   SentimentClass  4670 non-null   object \n",
      " 4   text            4670 non-null   object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 218.9+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_vaccine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     2634\n",
       "Positive    1467\n",
       "Negative     569\n",
       "Name: SentimentClass, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = {'1':'Positive','2':'Negative','0':'Neutral'}\n",
    "tweet_vaccine['SentimentClass'] = tweet_vaccine['SentimentClass'].map(sent)\n",
    "tweet_vaccine['SentimentClass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tweet_vaccine['SentimentClass'].value_counts().plot(kind='bar', width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweet_vaccine.iloc[:, 4].values\n",
    "y = tweet_vaccine.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer (max_features=250, min_df=7, max_df=0.8)\n",
    "X = vectorizer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4670, 250), (4670,), (4203, 250), (4203,), (467, 250), (467,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[246   3   2]\n",
      " [ 47 115   2]\n",
      " [ 30   6  16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86       251\n",
      "           1       0.93      0.70      0.80       164\n",
      "           2       0.80      0.31      0.44        52\n",
      "\n",
      "    accuracy                           0.81       467\n",
      "   macro avg       0.83      0.66      0.70       467\n",
      "weighted avg       0.82      0.81      0.79       467\n",
      "\n",
      "80.72805139186295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_predRF = rfc.predict(X_test)\n",
    "score_RF = rfc.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predRF))\n",
    "print(classification_report(y_test,y_predRF))\n",
    "print(accuracy_score(y_test, y_predRF) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[250   1   0]\n",
      " [ 52 110   2]\n",
      " [ 31   5  16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       251\n",
      "           1       0.95      0.67      0.79       164\n",
      "           2       0.89      0.31      0.46        52\n",
      "\n",
      "    accuracy                           0.81       467\n",
      "   macro avg       0.86      0.66      0.70       467\n",
      "weighted avg       0.84      0.81      0.79       467\n",
      "\n",
      "80.51391862955032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "y_predSVC = svclassifier.predict(X_test)\n",
    "score_SVC = svclassifier.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predSVC))\n",
    "print(classification_report(y_test,y_predSVC))\n",
    "print(accuracy_score(y_test, y_predSVC) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[247   4   0]\n",
      " [ 47 115   2]\n",
      " [ 33   7  12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.85       251\n",
      "           1       0.91      0.70      0.79       164\n",
      "           2       0.86      0.23      0.36        52\n",
      "\n",
      "    accuracy                           0.80       467\n",
      "   macro avg       0.84      0.64      0.67       467\n",
      "weighted avg       0.82      0.80      0.78       467\n",
      "\n",
      "80.08565310492506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "y_predNB = NB_model.predict(X_test)\n",
    "score_NB = NB_model.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predNB))\n",
    "print(classification_report(y_test,y_predNB))\n",
    "print(accuracy_score(y_test, y_predNB) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[247   4   0]\n",
      " [ 46 117   1]\n",
      " [ 33   5  14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.98      0.86       251\n",
      "           1       0.93      0.71      0.81       164\n",
      "           2       0.93      0.27      0.42        52\n",
      "\n",
      "    accuracy                           0.81       467\n",
      "   macro avg       0.87      0.66      0.69       467\n",
      "weighted avg       0.84      0.81      0.79       467\n",
      "\n",
      "80.94218415417559\n"
     ]
    }
   ],
   "source": [
    "LR_model = LogisticRegression(solver='lbfgs')\n",
    "LR_model.fit(X_train, y_train)\n",
    "y_predLR = LR_model.predict(X_test)\n",
    "score_LR = LR_model.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predLR))\n",
    "print(classification_report(y_test,y_predLR))\n",
    "print(accuracy_score(y_test, y_predLR) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[235  13   3]\n",
      " [111  51   2]\n",
      " [ 41   1  10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.94      0.74       251\n",
      "           1       0.78      0.31      0.45       164\n",
      "           2       0.67      0.19      0.30        52\n",
      "\n",
      "    accuracy                           0.63       467\n",
      "   macro avg       0.69      0.48      0.49       467\n",
      "weighted avg       0.68      0.63      0.59       467\n",
      "\n",
      "63.38329764453962\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier #K nearest neighbors\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "model_KNN.fit(X_train, y_train)\n",
    "y_predKNN = model_KNN.predict(X_test)\n",
    "score_KNN = model_KNN.score(X_test,y_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_predKNN))\n",
    "print(classification_report(y_test,y_predKNN))\n",
    "print(accuracy_score(y_test, y_predKNN) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+\n",
      "|     CLASSIFICATION     | ACCURACY |\n",
      "+========================+==========+\n",
      "| LogisticRegression     | 80.942   |\n",
      "+------------------------+----------+\n",
      "| RandomForest           | 80.728   |\n",
      "+------------------------+----------+\n",
      "| K-NearestNeighbors     | 63.383   |\n",
      "+------------------------+----------+\n",
      "| MultinominalNaiveBayes | 80.086   |\n",
      "+------------------------+----------+\n",
      "| SupportVector          | 80.514   |\n",
      "+------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from texttable import Texttable\n",
    "# texttable takes the first reocrd in the list as the column names\n",
    "# of the table\n",
    "l = [[\"CLASSIFICATION\", \"ACCURACY\"],['LogisticRegression', (score_LR * 100)],['RandomForest', (score_RF * 100)],['K-NearestNeighbors',(score_KNN * 100)],['MultinominalNaiveBayes',(score_NB * 100)], ['SupportVector', (score_SVC * 100)]]\n",
    "table = Texttable()\n",
    "table.add_rows(l)\n",
    "print(table.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
