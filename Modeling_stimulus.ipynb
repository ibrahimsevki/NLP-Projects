{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweet_stimulus = pd.read_csv((\"/Users/bahtinur/Desktop/Tweet/stimulus.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330775252339572737</td>\n",
       "      <td>2020-11-23 07:28:39</td>\n",
       "      <td>pandemic stimulus: cancel student loans by exe...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330775251664429061</td>\n",
       "      <td>2020-11-23 07:28:39</td>\n",
       "      <td>repmichaelwaltz  senrickscott  spaceforcedod ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1330775152179752964</td>\n",
       "      <td>2020-11-23 07:28:15</td>\n",
       "      <td>senrickscott  america   stimulus now   .  mil...</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1330775041685020672</td>\n",
       "      <td>2020-11-23 07:27:49</td>\n",
       "      <td>markets move higher as investors eye the   ele...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330775013746733057</td>\n",
       "      <td>2020-11-23 07:27:42</td>\n",
       "      <td>aerosol may not be good for the environment, b...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1330775252339572737  2020-11-23 07:28:39   \n",
       "1  1330775251664429061  2020-11-23 07:28:39   \n",
       "2  1330775152179752964  2020-11-23 07:28:15   \n",
       "3  1330775041685020672  2020-11-23 07:27:49   \n",
       "4  1330775013746733057  2020-11-23 07:27:42   \n",
       "\n",
       "                                           full_text  Sentiment SentimentClass  \n",
       "0  pandemic stimulus: cancel student loans by exe...   0.000000        Neutral  \n",
       "1   repmichaelwaltz  senrickscott  spaceforcedod ...   0.000000        Neutral  \n",
       "2   senrickscott  america   stimulus now   .  mil...   0.068182       Positive  \n",
       "3  markets move higher as investors eye the   ele...   0.250000       Positive  \n",
       "4  aerosol may not be good for the environment, b...   0.600000       Positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_stimulus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    pandemic stimulus: cancel student loans by exe...\n",
      "1     repmichaelwaltz  senrickscott  spaceforcedod ...\n",
      "2     senrickscott  america   stimulus now   .  mil...\n",
      "3    markets move higher as investors eye the   ele...\n",
      "4    aerosol may not be good for the environment, b...\n",
      "Name: full_text, dtype: object\n",
      "-------Remove Stop Word------\n",
      "0    pandemic stimulus: cancel student loans execut...\n",
      "1    repmichaelwaltz senrickscott spaceforcedod gov...\n",
      "2    senrickscott america stimulus . million americ...\n",
      "3    markets move higher investors eye election, on...\n",
      "4    aerosol may good environment, still remember o...\n",
      "Name: StopWords, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop = stopwords.words(\"english\")\n",
    "\n",
    "print((tweet_stimulus['full_text']).head())\n",
    "print('-------Remove Stop Word------')\n",
    "tweet_stimulus['StopWords'] = tweet_stimulus['full_text'].astype(str).apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "print((tweet_stimulus['StopWords']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    pandemic stimulus: cancel student loans execut...\n",
      "1    repmichaelwaltz senrickscott spaceforcedod gov...\n",
      "2    senrickscott america stimulus . million americ...\n",
      "3    markets move higher investors eye election, on...\n",
      "4    aerosol may good environment, still remember o...\n",
      "Name: StopWords, dtype: object\n",
      "-------Stemming------\n",
      "0    pandem stimulus: cancel student loan execut or...\n",
      "1    repmichaelwaltz senrickscott spaceforcedod gov...\n",
      "2    senrickscott america stimulu . million america...\n",
      "3    market move higher investor eye election, ongo...\n",
      "4    aerosol may good environment, still rememb ok ...\n",
      "Name: Stemming, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "print((tweet_stimulus['StopWords']).head())\n",
    "print('-------Stemming------')\n",
    "tweet_stimulus['Stemming'] = tweet_stimulus['StopWords'].astype(str).apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\n",
    "print((tweet_stimulus['Stemming']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    pandem stimulus: cancel student loan execut or...\n",
      "1    repmichaelwaltz senrickscott spaceforcedod gov...\n",
      "2    senrickscott america stimulu . million america...\n",
      "3    market move higher investor eye election, ongo...\n",
      "4    aerosol may good environment, still rememb ok ...\n",
      "Name: Stemming, dtype: object\n",
      "-------Lemmazation------\n",
      "0    pandem stimulus: cancel student loan execut or...\n",
      "1    repmichaelwaltz senrickscott spaceforcedod gov...\n",
      "2    senrickscott america stimulu . million america...\n",
      "3    market move higher investor eye election, ongo...\n",
      "4    aerosol may good environment, still rememb ok ...\n",
      "Name: Lemmatizing, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print((tweet_stimulus['Stemming']).head())\n",
    "print('-------Lemmazation------')\n",
    "tweet_stimulus['Lemmatizing'] = tweet_stimulus['Stemming'].astype(str).apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "print((tweet_stimulus['Lemmatizing']).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "text = tweet_stimulus[\"Lemmatizing\"]\n",
    "\n",
    "for i in range(0,len(text)):\n",
    "    textB = TextBlob(text[i])\n",
    "    sentiment = textB.sentiment.polarity\n",
    "    tweet_stimulus.at[i, 'Sentiment'] = sentiment\n",
    "    if sentiment <0.00:\n",
    "        SentimentClass = 'Negative'\n",
    "        tweet_stimulus.at[i, 'SentimentClass'] = SentimentClass \n",
    "    elif sentiment >0.00:\n",
    "        SentimentClass = 'Positive'\n",
    "        tweet_stimulus.at[i, 'SentimentClass'] = SentimentClass \n",
    "    else:\n",
    "        SentimentClass = 'Neutral'\n",
    "        tweet_stimulus.at[i, 'SentimentClass'] = SentimentClass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweet_stimulus.to_csv(\"/Users/bahtinur/Desktop/Tweet/stimulus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweet_stimulus = pd.read_csv((\"/Users/bahtinur/Desktop/Tweet/stimulus.csv\"), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentClass</th>\n",
       "      <th>Lemmatizing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330775252339572737</td>\n",
       "      <td>2020-11-23 07:28:39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>pandem stimulus: cancel student loan execut or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330775251664429061</td>\n",
       "      <td>2020-11-23 07:28:39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>repmichaelwaltz senrickscott spaceforcedod gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1330775152179752964</td>\n",
       "      <td>2020-11-23 07:28:15</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>Positive</td>\n",
       "      <td>senrickscott america stimulu . million america...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1330775041685020672</td>\n",
       "      <td>2020-11-23 07:27:49</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>market move higher investor eye election, ongo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330775013746733057</td>\n",
       "      <td>2020-11-23 07:27:42</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>aerosol may good environment, still rememb ok ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  Sentiment SentimentClass  \\\n",
       "0  1330775252339572737  2020-11-23 07:28:39   0.000000        Neutral   \n",
       "1  1330775251664429061  2020-11-23 07:28:39   0.000000        Neutral   \n",
       "2  1330775152179752964  2020-11-23 07:28:15   0.045455       Positive   \n",
       "3  1330775041685020672  2020-11-23 07:27:49   0.250000       Positive   \n",
       "4  1330775013746733057  2020-11-23 07:27:42   0.600000       Positive   \n",
       "\n",
       "                                         Lemmatizing  \n",
       "0  pandem stimulus: cancel student loan execut or...  \n",
       "1  repmichaelwaltz senrickscott spaceforcedod gov...  \n",
       "2  senrickscott america stimulu . million america...  \n",
       "3  market move higher investor eye election, ongo...  \n",
       "4  aerosol may good environment, still rememb ok ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_stimulus.drop(['StopWords', 'Stemming', 'full_text'], axis=1, inplace = True)\n",
    "tweet_stimulus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentClass</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330775252339572737</td>\n",
       "      <td>2020-11-23 07:28:39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>pandem stimulus: cancel student loan execut or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330775251664429061</td>\n",
       "      <td>2020-11-23 07:28:39</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>repmichaelwaltz senrickscott spaceforcedod gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1330775152179752964</td>\n",
       "      <td>2020-11-23 07:28:15</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>Positive</td>\n",
       "      <td>senrickscott america stimulu . million america...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1330775041685020672</td>\n",
       "      <td>2020-11-23 07:27:49</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>market move higher investor eye election, ongo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330775013746733057</td>\n",
       "      <td>2020-11-23 07:27:42</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>aerosol may good environment, still rememb ok ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  Sentiment SentimentClass  \\\n",
       "0  1330775252339572737  2020-11-23 07:28:39   0.000000        Neutral   \n",
       "1  1330775251664429061  2020-11-23 07:28:39   0.000000        Neutral   \n",
       "2  1330775152179752964  2020-11-23 07:28:15   0.045455       Positive   \n",
       "3  1330775041685020672  2020-11-23 07:27:49   0.250000       Positive   \n",
       "4  1330775013746733057  2020-11-23 07:27:42   0.600000       Positive   \n",
       "\n",
       "                                                text  \n",
       "0  pandem stimulus: cancel student loan execut or...  \n",
       "1  repmichaelwaltz senrickscott spaceforcedod gov...  \n",
       "2  senrickscott america stimulu . million america...  \n",
       "3  market move higher investor eye election, ongo...  \n",
       "4  aerosol may good environment, still rememb ok ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_stimulus.rename(columns={'Lemmatizing':'text'}, inplace=True)\n",
    "tweet_stimulus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = {'Positive':'1','Negative':'2','Neutral':'0'}\n",
    "tweet_stimulus['SentimentClass'] = tweet_stimulus['SentimentClass'].map(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4690 entries, 0 to 4689\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              4690 non-null   int64  \n",
      " 1   created_at      4690 non-null   object \n",
      " 2   Sentiment       4690 non-null   float64\n",
      " 3   SentimentClass  4690 non-null   object \n",
      " 4   text            4690 non-null   object \n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 219.8+ KB\n"
     ]
    }
   ],
   "source": [
    "tweet_stimulus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     2576\n",
       "Positive    1387\n",
       "Negative     727\n",
       "Name: SentimentClass, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = {'1':'Positive','2':'Negative','0':'Neutral'}\n",
    "tweet_stimulus['SentimentClass'] = tweet_stimulus['SentimentClass'].map(sent)\n",
    "tweet_stimulus['SentimentClass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "tweet_stimulus['SentimentClass'].value_counts().plot(kind='bar', width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweet_stimulus.iloc[:, 4].values\n",
    "y = tweet_stimulus.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer (max_features=250, min_df=7, max_df=0.8)\n",
    "X = vectorizer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4690, 250), (4690,), (4221, 250), (4221,), (469, 250), (469,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[252   3   7]\n",
      " [ 38  89   9]\n",
      " [ 42   6  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.96      0.85       262\n",
      "           1       0.91      0.65      0.76       136\n",
      "           2       0.59      0.32      0.42        71\n",
      "\n",
      "    accuracy                           0.78       469\n",
      "   macro avg       0.75      0.65      0.68       469\n",
      "weighted avg       0.78      0.78      0.76       469\n",
      "\n",
      "77.61194029850746\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_predRF = rfc.predict(X_test)\n",
    "score_RF = rfc.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predRF))\n",
    "print(classification_report(y_test,y_predRF))\n",
    "print(accuracy_score(y_test, y_predRF) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[262   0   0]\n",
      " [ 49  83   4]\n",
      " [ 45   5  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       262\n",
      "           1       0.94      0.61      0.74       136\n",
      "           2       0.84      0.30      0.44        71\n",
      "\n",
      "    accuracy                           0.78       469\n",
      "   macro avg       0.84      0.64      0.68       469\n",
      "weighted avg       0.81      0.78      0.75       469\n",
      "\n",
      "78.03837953091684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "y_predSVC = svclassifier.predict(X_test)\n",
    "score_SVC = svclassifier.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predSVC))\n",
    "print(classification_report(y_test,y_predSVC))\n",
    "print(accuracy_score(y_test, y_predSVC) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[247  14   1]\n",
      " [ 50  83   3]\n",
      " [ 46   4  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.82       262\n",
      "           1       0.82      0.61      0.70       136\n",
      "           2       0.84      0.30      0.44        71\n",
      "\n",
      "    accuracy                           0.75       469\n",
      "   macro avg       0.79      0.62      0.65       469\n",
      "weighted avg       0.77      0.75      0.73       469\n",
      "\n",
      "74.84008528784648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "NB_model = MultinomialNB()\n",
    "NB_model.fit(X_train, y_train)\n",
    "y_predNB = NB_model.predict(X_test)\n",
    "score_NB = NB_model.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predNB))\n",
    "print(classification_report(y_test,y_predNB))\n",
    "print(accuracy_score(y_test, y_predNB) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[257   2   3]\n",
      " [ 46  87   3]\n",
      " [ 44   6  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84       262\n",
      "           1       0.92      0.64      0.75       136\n",
      "           2       0.78      0.30      0.43        71\n",
      "\n",
      "    accuracy                           0.78       469\n",
      "   macro avg       0.81      0.64      0.68       469\n",
      "weighted avg       0.80      0.78      0.75       469\n",
      "\n",
      "77.82515991471215\n"
     ]
    }
   ],
   "source": [
    "LR_model = LogisticRegression(solver='lbfgs')\n",
    "LR_model.fit(X_train, y_train)\n",
    "y_predLR = LR_model.predict(X_test)\n",
    "score_LR = LR_model.score(X_test, y_test)\n",
    "print(confusion_matrix(y_test,y_predLR))\n",
    "print(classification_report(y_test,y_predLR))\n",
    "print(accuracy_score(y_test, y_predLR) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[244  12   6]\n",
      " [ 79  53   4]\n",
      " [ 61   1   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.76       262\n",
      "           1       0.80      0.39      0.52       136\n",
      "           2       0.47      0.13      0.20        71\n",
      "\n",
      "    accuracy                           0.65       469\n",
      "   macro avg       0.64      0.48      0.49       469\n",
      "weighted avg       0.66      0.65      0.60       469\n",
      "\n",
      "65.2452025586354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier #K nearest neighbors\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "model_KNN.fit(X_train, y_train)\n",
    "y_predKNN = model_KNN.predict(X_test)\n",
    "score_KNN = model_KNN.score(X_test,y_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_predKNN))\n",
    "print(classification_report(y_test,y_predKNN))\n",
    "print(accuracy_score(y_test, y_predKNN) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+\n",
      "|     CLASSIFICATION     | ACCURACY |\n",
      "+========================+==========+\n",
      "| LogisticRegression     | 77.825   |\n",
      "+------------------------+----------+\n",
      "| RandomForest           | 77.612   |\n",
      "+------------------------+----------+\n",
      "| K-NearestNeighbors     | 65.245   |\n",
      "+------------------------+----------+\n",
      "| MultinominalNaiveBayes | 74.840   |\n",
      "+------------------------+----------+\n",
      "| SupportVector          | 78.038   |\n",
      "+------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from texttable import Texttable\n",
    "# texttable takes the first reocrd in the list as the column names\n",
    "# of the table\n",
    "l = [[\"CLASSIFICATION\", \"ACCURACY\"],['LogisticRegression', (score_LR * 100)],['RandomForest', (score_RF * 100)],['K-NearestNeighbors',(score_KNN * 100)],['MultinominalNaiveBayes',(score_NB * 100)], ['SupportVector', (score_SVC * 100)]]\n",
    "table = Texttable()\n",
    "table.add_rows(l)\n",
    "print(table.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
